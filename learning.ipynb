{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from data_handling.model_info import load_model_info\n",
    "from data_handling import DataLoader, Conversion_Layers\n",
    "from network import loss, cnn_definition_paper\n",
    "\n",
    "from star_representation import StarRepresentation\n",
    "from dash_repesentation import RemoveCameraEffect, DashRepresentation\n",
    "from reverse_op import PODestarisation\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "bop_path  = '/export/jesse/BOP'\n",
    "dataset = 'tless'\n",
    "\n",
    "dataset_path = f'{bop_path}/{dataset}'\n",
    "\n",
    "train = ['train_pbr', 'train_primesense']\n",
    "test = ['test_primesense']\n",
    "\n",
    "xyDim = 112\n",
    "strides = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def pred_loss(true, pred):\n",
    "    return pred\n",
    "\n",
    "def totuplething(x1, x2, x3, x4, x5, x6, x7):\n",
    "    return ((x1, x2, x3, x4, x7, x5, x6), x6)\n",
    "\n",
    "for oiu in range(1,31):\n",
    "    print('Object ', oiu)\n",
    "    model_info = load_model_info(dataset_path, oiu, verbose=1)\n",
    "    train_data = DataLoader.load_gt_data([f'{dataset_path}/{d}' for d in train ], oiu)\n",
    "    print(f'Found train data for {len(train_data)} occurencies of object {oiu}, where {len([d for d in train_data if \"primesense\" in d[\"root\"]])} origined from primesense.')\n",
    "\n",
    "    mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "    with mirrored_strategy.scope():    \n",
    "        inputs, valid_po, isvalid, depth, segmentation = Conversion_Layers.create_Dataset_conversion_layers(xyDim, xyDim, model_info, strides)\n",
    "\n",
    "        valid_dash = DashRepresentation(model_info[\"symmetries_discrete\"][0][:3,-1] / 2. if len(model_info[\"symmetries_discrete\"]) > 0 else 0 )(inputs['roationmatrix'], valid_po)\n",
    "        valid_po_star = StarRepresentation(model_info)(valid_po)\n",
    "\n",
    "        cnn_po_star, cnn_po_dash, cnn_w_px, cnn_w_d, cnn_seg = cnn_definition_paper.rgb255_to_obj_net(inputs['rgb'])\n",
    "        dash_image = RemoveCameraEffect(strides)(cnn_po_dash, inputs['camera_matrix'], inputs['coord_offset'])\n",
    "        \n",
    "        csl_trainable_layers = tf.keras.Model([inputs['rgb'], inputs['depth'], inputs['camera_matrix'], inputs['coord_offset']],\n",
    "                                              [cnn_po_star, dash_image, cnn_w_px, cnn_w_d, cnn_seg])\n",
    "                \n",
    "        po_image = PODestarisation(model_info,amount_of_instances = 1)(cnn_po_star, dash_image, isvalid, inputs['roationmatrix'])\n",
    "        po_uv, po_cam = loss.Po_to_Img()(po_image, inputs['camera_matrix'], inputs['roationmatrix'], inputs['translation'])\n",
    "\n",
    "    #     diff_po = Lambda(squared_diff_of_pos, name='po_diff')((po_image, valid_po, isvalid))\n",
    "        diff_postar = loss.AvgSqrDiff_of_validPixels(name='pos_diff')(cnn_po_star, valid_po_star, isvalid)\n",
    "        diff_vo = loss.AvgSqrDiff_of_validPixels(name='vo_diff')(dash_image, valid_dash, isvalid)\n",
    "        (seg_loss, seg_met, seg_fgmet) = loss.Seg_Loss(name='seg')(cnn_seg, segmentation)  \n",
    "\n",
    "        sig2inv = loss.ToOmega()(cnn_w_px, isvalid)\n",
    "        po_uv_diff = loss.UV_diff(strides)(po_uv, inputs['coord_offset'])\n",
    "        lw2_loss, chi2error = loss.Avg_nllh(name='w2')(sig2inv, po_uv_diff, isvalid)\n",
    "\n",
    "        sig1inv =  loss.ToOmega()(cnn_w_d, isvalid)\n",
    "        po_depth_diff = loss.D_diff()(po_cam, depth)\n",
    "        lw1_loss, chi2error_d = loss.Avg_nllh(name='w1')(sig1inv, po_depth_diff, isvalid)\n",
    "#         lw1_loss, chi2error_d = Lambda(wp_loss_wd, name='w1')((cnn_w_d, po_cam, depth, isvalid))\n",
    "\n",
    "        train_povoseg_model = tf.keras.Model(inputs.values(), (diff_postar, diff_vo, seg_loss, seg_met, seg_fgmet))\n",
    "        train_model = tf.keras.Model(inputs.values(), (diff_postar, diff_vo, seg_loss, seg_met, seg_fgmet,\n",
    "                                                      lw2_loss, chi2error, lw1_loss, chi2error_d))\n",
    "\n",
    "        train_povoseg_model.compile(Adam(0.0001,  amsgrad=True),\n",
    "                            loss = pred_loss,\n",
    "                            loss_weights=(1,1,1,0,0)\n",
    "                          )\n",
    "\n",
    "        train_model.compile(Adam(0.0001,  amsgrad=True),\n",
    "                            loss = pred_loss,\n",
    "                            loss_weights=(1,1,1,0,0,\n",
    "                                          1,0,1,0)\n",
    "                           ) \n",
    "        \n",
    "#         train_povoseg_model.fit(Dataset(train_data,xyDim, times=2, group_size=5, random=True).cache(f\"{dataset_path}/cached_training_data/{oiu}t2g5\").batch(80).prefetch(20).map(totuplething),\n",
    "#                         epochs=2,\n",
    "#                         verbose=1,\n",
    "#                         workers=8,\n",
    "#                         max_queue_size=100,\n",
    "#                         use_multiprocessing=True)\n",
    "#         train_povoseg_model.save_weights(ff'{dataset_path}/saved_weights/new_{oiu}_train_povoseg_2e')\n",
    "\n",
    "        train_model.fit(DataLoader.Dataset(train_data,xyDim, times=2, group_size=5, random=True).cache(f\"{dataset_path}/cached_training_data/{oiu}t2g5\").batch(40).prefetch(20).map(totuplething),\n",
    "                                epochs=10,\n",
    "                                verbose=1,\n",
    "                                workers=8,\n",
    "                                max_queue_size=100,\n",
    "                                use_multiprocessing=True)\n",
    "        train_model.save_weights(f'{dataset_path}/saved_weights/csl_o{oiu}_train_model_10e')\n",
    "        csl_trainable_layers.save(f'{dataset_path}/saved_models/csl_o{oiu}_trainable_layers')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
